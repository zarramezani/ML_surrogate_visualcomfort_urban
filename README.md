ML_surrogate_visualcomdort_urban
In this repository, you will find the documents and data used in the research conducted by Zahra Ramezani, Zahra Sadat Zomorodian, Mohammad Tahsildoost

Abstract

Visual comfort is a key dimension of environmental quality in urban fabrics, influencing spatial perception, user satisfaction, and social well-being. However, its assessment remains challenging due to its multidimensional nature and the combined effects of geometric and climatic factors. This study proposes a data-driven framework for evaluating and predicting façade-level visual comfort performance classes derived from six standard-based metrics at the urban-block scale. Parametric modeling in Grasshopper, using the Honeybee and Ladybug plug-ins, was employed to generate a wide range of synthetic urban scenarios for the climate of Tehran. For each sensor point, six metrics—Vertical Sky Component (VSC), Vertical Daylight Factor (VDF), Sunlight Autonomy (SA), Direct Sun Hours (DSH), Peak Irradiance, and Visibility Percent (VP)— were computed and categorized into performance classes together with geometric descriptors of sensor position and surrounding obstructions. Five machine-learning classifiers were trained to predict performance classes for each metric; among them, LightGBM achieved the best performance, with mean accuracy of 0.95 and macro-averaged F1-score of 0.92. SHAP-based sensitivity analysis showed that façade orientation, spacing between blocks, building height, and sensor-obstruction distance are the dominant predictors of daylight, solar exposure, and view quality, whereas block plan dimensions and sensor distances to façade edges play a secondary role. Overall, the proposed framework enables fast, ML-based mapping of façade-level visual comfort performance in urban environments and can serve as an efficient decision-support tool for screening and optimizing urban design options at early planning stages.
